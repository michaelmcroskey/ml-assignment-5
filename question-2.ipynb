{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Question 2\n",
    "Consider the Mammography dataset available on the resources tab. There are two classes: class 1 indicates calcification (cancer) and class 0 indicates no calcification (no cancer). Thus, the class 1 is the positive class and class 0 is the negative class. You are required to use and compare a neural network classifier (MLPClassifier in scikit-learn, for example) and a decision tree classifier (DecisionTreeClassifier in scikit-learn, for example). You will use 10-fold cross-validation (StratifiedKFold in scikit-learn; also look at cross_val_score) to compare the two classifiers. Please identify classifier is statistically significantly better at 95% confidence when using Error as a metric. Please identify which classifier is statistically significantly better at 95% confidence when using AUC or F-measure as a metric.  Please also discuss if there are any differences in classifier performance when using AUC / F-measure or Error as the evaluation metric.  (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "*Extra Credit: Consider optimizing the decision tree pruning criterion or MLP learning rate / number of units and see if the performance can be improved. (5 points)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11183.000000</td>\n",
       "      <td>11183.000000</td>\n",
       "      <td>11183.000000</td>\n",
       "      <td>11183.000000</td>\n",
       "      <td>11183.000000</td>\n",
       "      <td>11183.000000</td>\n",
       "      <td>11183.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.631014</td>\n",
       "      <td>106.292408</td>\n",
       "      <td>0.013124</td>\n",
       "      <td>2.037123</td>\n",
       "      <td>11.476447</td>\n",
       "      <td>0.310368</td>\n",
       "      <td>1.023250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.903782</td>\n",
       "      <td>226.060108</td>\n",
       "      <td>0.022182</td>\n",
       "      <td>2.369981</td>\n",
       "      <td>30.371760</td>\n",
       "      <td>0.328180</td>\n",
       "      <td>0.150702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.990000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.484500</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>3.981000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>190.650000</td>\n",
       "      <td>1256.000000</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>24.768000</td>\n",
       "      <td>728.770000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  A             B             C             D             E  \\\n",
       "count  11183.000000  11183.000000  11183.000000  11183.000000  11183.000000   \n",
       "mean       4.631014    106.292408      0.013124      2.037123     11.476447   \n",
       "std        5.903782    226.060108      0.022182      2.369981     30.371760   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        3.990000     17.000000      0.008000      0.000000      0.000000   \n",
       "75%        6.484500     89.000000      0.018000      3.981000      0.000000   \n",
       "max      190.650000   1256.000000      0.667000     24.768000    728.770000   \n",
       "\n",
       "                  F         Class  \n",
       "count  11183.000000  11183.000000  \n",
       "mean       0.310368      1.023250  \n",
       "std        0.328180      0.150702  \n",
       "min        0.000000      1.000000  \n",
       "25%        0.000000      1.000000  \n",
       "50%        0.000000      1.000000  \n",
       "75%        0.644000      1.000000  \n",
       "max        0.950000      2.000000  "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"Class\"]\n",
    "df = pd.read_csv('data/ism.data', names=features)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y = df['Class']\n",
    "x = df.drop(['Class'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Neural Network Classifier: MLPClassifier\n",
    "### cross_val_score\n",
    "Implements stratified k fold when given the integer value for cv parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.38233871\n",
      "Iteration 2, loss = 0.28318539\n",
      "Iteration 3, loss = 0.22969765\n",
      "Iteration 4, loss = 0.21128260\n",
      "Iteration 5, loss = 0.18456440\n",
      "Iteration 6, loss = 0.22189577\n",
      "Iteration 7, loss = 0.20086695\n",
      "Iteration 8, loss = 0.15835074\n",
      "Iteration 9, loss = 0.14090748\n",
      "Iteration 10, loss = 0.13236506\n",
      "Iteration 11, loss = 0.12217124\n",
      "Iteration 12, loss = 0.11940119\n",
      "Iteration 13, loss = 0.11208687\n",
      "Iteration 14, loss = 0.10816281\n",
      "Iteration 15, loss = 0.10431854\n",
      "Iteration 16, loss = 0.09818553\n",
      "Iteration 17, loss = 0.09738807\n",
      "Iteration 18, loss = 0.09410910\n",
      "Iteration 19, loss = 0.24137673\n",
      "Iteration 20, loss = 0.11575702\n",
      "Iteration 21, loss = 0.10289540\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.38472976\n",
      "Iteration 2, loss = 0.28363146\n",
      "Iteration 3, loss = 0.23100174\n",
      "Iteration 4, loss = 0.27404273\n",
      "Iteration 5, loss = 0.19966675\n",
      "Iteration 6, loss = 0.17146349\n",
      "Iteration 7, loss = 0.15639325\n",
      "Iteration 8, loss = 0.14210221\n",
      "Iteration 9, loss = 0.13288028\n",
      "Iteration 10, loss = 0.12708285\n",
      "Iteration 11, loss = 0.12517932\n",
      "Iteration 12, loss = 0.12338417\n",
      "Iteration 13, loss = 0.11255145\n",
      "Iteration 14, loss = 0.10908164\n",
      "Iteration 15, loss = 0.10311011\n",
      "Iteration 16, loss = 0.10348551\n",
      "Iteration 17, loss = 0.09861052\n",
      "Iteration 18, loss = 0.09516425\n",
      "Iteration 19, loss = 0.26145464\n",
      "Iteration 20, loss = 0.12425288\n",
      "Iteration 21, loss = 0.10592077\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.38315227\n",
      "Iteration 2, loss = 0.28598907\n",
      "Iteration 3, loss = 0.23154996\n",
      "Iteration 4, loss = 0.31956368\n",
      "Iteration 5, loss = 0.20503028\n",
      "Iteration 6, loss = 0.17453340\n",
      "Iteration 7, loss = 0.15879961\n",
      "Iteration 8, loss = 0.14334087\n",
      "Iteration 9, loss = 0.13152161\n",
      "Iteration 10, loss = 0.12476668\n",
      "Iteration 11, loss = 0.11850064\n",
      "Iteration 12, loss = 0.11507540\n",
      "Iteration 13, loss = 0.11123865\n",
      "Iteration 14, loss = 0.10795631\n",
      "Iteration 15, loss = 0.10258349\n",
      "Iteration 16, loss = 0.09681298\n",
      "Iteration 17, loss = 0.09642866\n",
      "Iteration 18, loss = 0.09570418\n",
      "Iteration 19, loss = 0.13968946\n",
      "Iteration 20, loss = 0.09883471\n",
      "Iteration 21, loss = 0.09280436\n",
      "Iteration 22, loss = 0.09146712\n",
      "Iteration 23, loss = 0.08603490\n",
      "Iteration 24, loss = 0.08799607\n",
      "Iteration 25, loss = 0.08351959\n",
      "Iteration 26, loss = 0.08594647\n",
      "Iteration 27, loss = 0.08064398\n",
      "Iteration 28, loss = 0.08197920\n",
      "Iteration 29, loss = 0.08011548\n",
      "Iteration 30, loss = 0.07916041\n",
      "Iteration 31, loss = 0.08056515\n",
      "Iteration 32, loss = 0.07557530\n",
      "Iteration 33, loss = 0.08077808\n",
      "Iteration 34, loss = 0.08260497\n",
      "Iteration 35, loss = 0.08291987\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.38694246\n",
      "Iteration 2, loss = 0.28939854\n",
      "Iteration 3, loss = 0.23667768\n",
      "Iteration 4, loss = 0.20161426\n",
      "Iteration 5, loss = 0.17583290\n",
      "Iteration 6, loss = 0.16460272\n",
      "Iteration 7, loss = 0.27338089\n",
      "Iteration 8, loss = 0.18323979\n",
      "Iteration 9, loss = 0.15367192\n",
      "Iteration 10, loss = 0.13689804\n",
      "Iteration 11, loss = 0.12677236\n",
      "Iteration 12, loss = 0.12179215\n",
      "Iteration 13, loss = 0.11289764\n",
      "Iteration 14, loss = 0.10938638\n",
      "Iteration 15, loss = 0.10610195\n",
      "Iteration 16, loss = 0.10253511\n",
      "Iteration 17, loss = 0.10121265\n",
      "Iteration 18, loss = 0.10095091\n",
      "Iteration 19, loss = 0.09511241\n",
      "Iteration 20, loss = 0.09282672\n",
      "Iteration 21, loss = 0.09029888\n",
      "Iteration 22, loss = 0.08780592\n",
      "Iteration 23, loss = 0.08687974\n",
      "Iteration 24, loss = 0.08507110\n",
      "Iteration 25, loss = 0.08742122\n",
      "Iteration 26, loss = 0.09149069\n",
      "Iteration 27, loss = 0.08861766\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.38709945\n",
      "Iteration 2, loss = 0.28695343\n",
      "Iteration 3, loss = 0.23231163\n",
      "Iteration 4, loss = 0.20068324\n",
      "Iteration 5, loss = 0.17404508\n",
      "Iteration 6, loss = 0.16208463\n",
      "Iteration 7, loss = 0.28287776\n",
      "Iteration 8, loss = 0.18456218\n",
      "Iteration 9, loss = 0.15274525\n",
      "Iteration 10, loss = 0.13424902\n",
      "Iteration 11, loss = 0.12494906\n",
      "Iteration 12, loss = 0.11969247\n",
      "Iteration 13, loss = 0.11208924\n",
      "Iteration 14, loss = 0.10992610\n",
      "Iteration 15, loss = 0.10486059\n",
      "Iteration 16, loss = 0.10146737\n",
      "Iteration 17, loss = 0.10021736\n",
      "Iteration 18, loss = 0.09678055\n",
      "Iteration 19, loss = 0.09632588\n",
      "Iteration 20, loss = 0.09183285\n",
      "Iteration 21, loss = 0.09462595\n",
      "Iteration 22, loss = 0.09033015\n",
      "Iteration 23, loss = 0.08705275\n",
      "Iteration 24, loss = 0.08419171\n",
      "Iteration 25, loss = 0.08526005\n",
      "Iteration 26, loss = 0.08261722\n",
      "Iteration 27, loss = 0.11039123\n",
      "Iteration 28, loss = 0.08660464\n",
      "Iteration 29, loss = 0.08504863\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.38124098\n",
      "Iteration 2, loss = 0.28480127\n",
      "Iteration 3, loss = 0.22874730\n",
      "Iteration 4, loss = 0.19891306\n",
      "Iteration 5, loss = 0.17188267\n",
      "Iteration 6, loss = 0.17146623\n",
      "Iteration 7, loss = 0.24589521\n",
      "Iteration 8, loss = 0.17109458\n",
      "Iteration 9, loss = 0.14447625\n",
      "Iteration 10, loss = 0.13028550\n",
      "Iteration 11, loss = 0.12463394\n",
      "Iteration 12, loss = 0.11874387\n",
      "Iteration 13, loss = 0.11193776\n",
      "Iteration 14, loss = 0.10798197\n",
      "Iteration 15, loss = 0.10497106\n",
      "Iteration 16, loss = 0.10072634\n",
      "Iteration 17, loss = 0.09857691\n",
      "Iteration 18, loss = 0.09545598\n",
      "Iteration 19, loss = 0.09607034\n",
      "Iteration 20, loss = 0.09212446\n",
      "Iteration 21, loss = 0.09084610\n",
      "Iteration 22, loss = 0.08659692\n",
      "Iteration 23, loss = 0.08690280\n",
      "Iteration 24, loss = 0.08385008\n",
      "Iteration 25, loss = 0.08326281\n",
      "Iteration 26, loss = 0.08400651\n",
      "Iteration 27, loss = 0.08395280\n",
      "Iteration 28, loss = 0.11036444\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.38698097\n",
      "Iteration 2, loss = 0.28520679\n",
      "Iteration 3, loss = 0.22981052\n",
      "Iteration 4, loss = 0.19866811\n",
      "Iteration 5, loss = 0.17566201\n",
      "Iteration 6, loss = 0.16996563\n",
      "Iteration 7, loss = 0.15618181\n",
      "Iteration 8, loss = 0.22446616\n",
      "Iteration 9, loss = 0.14737955\n",
      "Iteration 10, loss = 0.13064983\n",
      "Iteration 11, loss = 0.12421650\n",
      "Iteration 12, loss = 0.11811615\n",
      "Iteration 13, loss = 0.11051142\n",
      "Iteration 14, loss = 0.10759475\n",
      "Iteration 15, loss = 0.10481650\n",
      "Iteration 16, loss = 0.09956810\n",
      "Iteration 17, loss = 0.09727642\n",
      "Iteration 18, loss = 0.09320962\n",
      "Iteration 19, loss = 0.09173985\n",
      "Iteration 20, loss = 0.09157152\n",
      "Iteration 21, loss = 0.08788964\n",
      "Iteration 22, loss = 0.08607108\n",
      "Iteration 23, loss = 0.08915649\n",
      "Iteration 24, loss = 0.10232392\n",
      "Iteration 25, loss = 0.08584608\n",
      "Iteration 26, loss = 0.08130130\n",
      "Iteration 27, loss = 0.08371145\n",
      "Iteration 28, loss = 0.16202726\n",
      "Iteration 29, loss = 0.11699226\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.39190492\n",
      "Iteration 2, loss = 0.28452639\n",
      "Iteration 3, loss = 0.24938615\n",
      "Iteration 4, loss = 0.21041736\n",
      "Iteration 5, loss = 0.18005568\n",
      "Iteration 6, loss = 0.16675027\n",
      "Iteration 7, loss = 0.15201235\n",
      "Iteration 8, loss = 0.16526319\n",
      "Iteration 9, loss = 0.13436269\n",
      "Iteration 10, loss = 0.13697477\n",
      "Iteration 11, loss = 0.12107048\n",
      "Iteration 12, loss = 0.11667339\n",
      "Iteration 13, loss = 0.11103042\n",
      "Iteration 14, loss = 0.10950596\n",
      "Iteration 15, loss = 0.11129761\n",
      "Iteration 16, loss = 0.10336334\n",
      "Iteration 17, loss = 0.09995632\n",
      "Iteration 18, loss = 0.09435230\n",
      "Iteration 19, loss = 0.10277755\n",
      "Iteration 20, loss = 0.09749407\n",
      "Iteration 21, loss = 0.08964161\n",
      "Iteration 22, loss = 0.09511067\n",
      "Iteration 23, loss = 0.11917350\n",
      "Iteration 24, loss = 0.09009605\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.39308011\n",
      "Iteration 2, loss = 0.28570300\n",
      "Iteration 3, loss = 0.23535190\n",
      "Iteration 4, loss = 0.22321196\n",
      "Iteration 5, loss = 0.19336619\n",
      "Iteration 6, loss = 0.16956843\n",
      "Iteration 7, loss = 0.15783624\n",
      "Iteration 8, loss = 0.15144097\n",
      "Iteration 9, loss = 0.13638851\n",
      "Iteration 10, loss = 0.15252847\n",
      "Iteration 11, loss = 0.14871346\n",
      "Iteration 12, loss = 0.12408308\n",
      "Iteration 13, loss = 0.11424790\n",
      "Iteration 14, loss = 0.11050621\n",
      "Iteration 15, loss = 0.10426818\n",
      "Iteration 16, loss = 0.10282350\n",
      "Iteration 17, loss = 0.09944018\n",
      "Iteration 18, loss = 0.09380094\n",
      "Iteration 19, loss = 0.09269244\n",
      "Iteration 20, loss = 0.09286106\n",
      "Iteration 21, loss = 0.08768003\n",
      "Iteration 22, loss = 0.09205011\n",
      "Iteration 23, loss = 0.10597650\n",
      "Iteration 24, loss = 0.08651939\n",
      "Iteration 25, loss = 0.08391317\n",
      "Iteration 26, loss = 0.08534003\n",
      "Iteration 27, loss = 0.08410900\n",
      "Iteration 28, loss = 0.08427225\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.38706241\n",
      "Iteration 2, loss = 0.28255256\n",
      "Iteration 3, loss = 0.23049432\n",
      "Iteration 4, loss = 0.20180769\n",
      "Iteration 5, loss = 0.17717936\n",
      "Iteration 6, loss = 0.16178376\n",
      "Iteration 7, loss = 0.15021221\n",
      "Iteration 8, loss = 0.13718237\n",
      "Iteration 9, loss = 0.16825668\n",
      "Iteration 10, loss = 0.12540542\n",
      "Iteration 11, loss = 0.11612399\n",
      "Iteration 12, loss = 0.10940787\n",
      "Iteration 13, loss = 0.10582928\n",
      "Iteration 14, loss = 0.10308228\n",
      "Iteration 15, loss = 0.12313812\n",
      "Iteration 16, loss = 0.09798474\n",
      "Iteration 17, loss = 0.09366842\n",
      "Iteration 18, loss = 0.08988267\n",
      "Iteration 19, loss = 0.08855160\n",
      "Iteration 20, loss = 0.09133073\n",
      "Iteration 21, loss = 0.08545720\n",
      "Iteration 22, loss = 0.08259001\n",
      "Iteration 23, loss = 0.08297788\n",
      "Iteration 24, loss = 0.08268240\n",
      "Iteration 25, loss = 0.08133864\n",
      "Iteration 26, loss = 0.08105042\n",
      "Iteration 27, loss = 0.07883693\n",
      "Iteration 28, loss = 0.08352102\n",
      "Iteration 29, loss = 0.12294329\n",
      "Iteration 30, loss = 0.10074191\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.38233871\n",
      "Iteration 2, loss = 0.28318539\n",
      "Iteration 3, loss = 0.22969765\n",
      "Iteration 4, loss = 0.21128260\n",
      "Iteration 5, loss = 0.18456440\n",
      "Iteration 6, loss = 0.22189577\n",
      "Iteration 7, loss = 0.20086695\n",
      "Iteration 8, loss = 0.15835074\n",
      "Iteration 9, loss = 0.14090748\n",
      "Iteration 10, loss = 0.13236506\n",
      "Iteration 11, loss = 0.12217124\n",
      "Iteration 12, loss = 0.11940119\n",
      "Iteration 13, loss = 0.11208687\n",
      "Iteration 14, loss = 0.10816281\n",
      "Iteration 15, loss = 0.10431854\n",
      "Iteration 16, loss = 0.09818553\n",
      "Iteration 17, loss = 0.09738807\n",
      "Iteration 18, loss = 0.09410910\n",
      "Iteration 19, loss = 0.24137673\n",
      "Iteration 20, loss = 0.11575702\n",
      "Iteration 21, loss = 0.10289540\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.38472976\n",
      "Iteration 2, loss = 0.28363146\n",
      "Iteration 3, loss = 0.23100174\n",
      "Iteration 4, loss = 0.27404273\n",
      "Iteration 5, loss = 0.19966675\n",
      "Iteration 6, loss = 0.17146349\n",
      "Iteration 7, loss = 0.15639325\n",
      "Iteration 8, loss = 0.14210221\n",
      "Iteration 9, loss = 0.13288028\n",
      "Iteration 10, loss = 0.12708285\n",
      "Iteration 11, loss = 0.12517932\n",
      "Iteration 12, loss = 0.12338417\n",
      "Iteration 13, loss = 0.11255145\n",
      "Iteration 14, loss = 0.10908164\n",
      "Iteration 15, loss = 0.10311011\n",
      "Iteration 16, loss = 0.10348551\n",
      "Iteration 17, loss = 0.09861052\n",
      "Iteration 18, loss = 0.09516425\n",
      "Iteration 19, loss = 0.26145464\n",
      "Iteration 20, loss = 0.12425288\n",
      "Iteration 21, loss = 0.10592077\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.38315227\n",
      "Iteration 2, loss = 0.28598907\n",
      "Iteration 3, loss = 0.23154996\n",
      "Iteration 4, loss = 0.31956368\n",
      "Iteration 5, loss = 0.20503028\n",
      "Iteration 6, loss = 0.17453340\n",
      "Iteration 7, loss = 0.15879961\n",
      "Iteration 8, loss = 0.14334087\n",
      "Iteration 9, loss = 0.13152161\n",
      "Iteration 10, loss = 0.12476668\n",
      "Iteration 11, loss = 0.11850064\n",
      "Iteration 12, loss = 0.11507540\n",
      "Iteration 13, loss = 0.11123865\n",
      "Iteration 14, loss = 0.10795631\n",
      "Iteration 15, loss = 0.10258349\n",
      "Iteration 16, loss = 0.09681298\n",
      "Iteration 17, loss = 0.09642866\n",
      "Iteration 18, loss = 0.09570418\n",
      "Iteration 19, loss = 0.13968946\n",
      "Iteration 20, loss = 0.09883471\n",
      "Iteration 21, loss = 0.09280436\n",
      "Iteration 22, loss = 0.09146712\n",
      "Iteration 23, loss = 0.08603490\n",
      "Iteration 24, loss = 0.08799607\n",
      "Iteration 25, loss = 0.08351959\n",
      "Iteration 26, loss = 0.08594647\n",
      "Iteration 27, loss = 0.08064398\n",
      "Iteration 28, loss = 0.08197920\n",
      "Iteration 29, loss = 0.08011548\n",
      "Iteration 30, loss = 0.07916041\n",
      "Iteration 31, loss = 0.08056515\n",
      "Iteration 32, loss = 0.07557530\n",
      "Iteration 33, loss = 0.08077808\n",
      "Iteration 34, loss = 0.08260497\n",
      "Iteration 35, loss = 0.08291987\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.38694246\n",
      "Iteration 2, loss = 0.28939854\n",
      "Iteration 3, loss = 0.23667768\n",
      "Iteration 4, loss = 0.20161426\n",
      "Iteration 5, loss = 0.17583290\n",
      "Iteration 6, loss = 0.16460272\n",
      "Iteration 7, loss = 0.27338089\n",
      "Iteration 8, loss = 0.18323979\n",
      "Iteration 9, loss = 0.15367192\n",
      "Iteration 10, loss = 0.13689804\n",
      "Iteration 11, loss = 0.12677236\n",
      "Iteration 12, loss = 0.12179215\n",
      "Iteration 13, loss = 0.11289764\n",
      "Iteration 14, loss = 0.10938638\n",
      "Iteration 15, loss = 0.10610195\n",
      "Iteration 16, loss = 0.10253511\n",
      "Iteration 17, loss = 0.10121265\n",
      "Iteration 18, loss = 0.10095091\n",
      "Iteration 19, loss = 0.09511241\n",
      "Iteration 20, loss = 0.09282672\n",
      "Iteration 21, loss = 0.09029888\n",
      "Iteration 22, loss = 0.08780592\n",
      "Iteration 23, loss = 0.08687974\n",
      "Iteration 24, loss = 0.08507110\n",
      "Iteration 25, loss = 0.08742122\n",
      "Iteration 26, loss = 0.09149069\n",
      "Iteration 27, loss = 0.08861766\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.38709945\n",
      "Iteration 2, loss = 0.28695343\n",
      "Iteration 3, loss = 0.23231163\n",
      "Iteration 4, loss = 0.20068324\n",
      "Iteration 5, loss = 0.17404508\n",
      "Iteration 6, loss = 0.16208463\n",
      "Iteration 7, loss = 0.28287776\n",
      "Iteration 8, loss = 0.18456218\n",
      "Iteration 9, loss = 0.15274525\n",
      "Iteration 10, loss = 0.13424902\n",
      "Iteration 11, loss = 0.12494906\n",
      "Iteration 12, loss = 0.11969247\n",
      "Iteration 13, loss = 0.11208924\n",
      "Iteration 14, loss = 0.10992610\n",
      "Iteration 15, loss = 0.10486059\n",
      "Iteration 16, loss = 0.10146737\n",
      "Iteration 17, loss = 0.10021736\n",
      "Iteration 18, loss = 0.09678055\n",
      "Iteration 19, loss = 0.09632588\n",
      "Iteration 20, loss = 0.09183285\n",
      "Iteration 21, loss = 0.09462595\n",
      "Iteration 22, loss = 0.09033015\n",
      "Iteration 23, loss = 0.08705275\n",
      "Iteration 24, loss = 0.08419171\n",
      "Iteration 25, loss = 0.08526005\n",
      "Iteration 26, loss = 0.08261722\n",
      "Iteration 27, loss = 0.11039123\n",
      "Iteration 28, loss = 0.08660464\n",
      "Iteration 29, loss = 0.08504863\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.38124098\n",
      "Iteration 2, loss = 0.28480127\n",
      "Iteration 3, loss = 0.22874730\n",
      "Iteration 4, loss = 0.19891306\n",
      "Iteration 5, loss = 0.17188267\n",
      "Iteration 6, loss = 0.17146623\n",
      "Iteration 7, loss = 0.24589521\n",
      "Iteration 8, loss = 0.17109458\n",
      "Iteration 9, loss = 0.14447625\n",
      "Iteration 10, loss = 0.13028550\n",
      "Iteration 11, loss = 0.12463394\n",
      "Iteration 12, loss = 0.11874387\n",
      "Iteration 13, loss = 0.11193776\n",
      "Iteration 14, loss = 0.10798197\n",
      "Iteration 15, loss = 0.10497106\n",
      "Iteration 16, loss = 0.10072634\n",
      "Iteration 17, loss = 0.09857691\n",
      "Iteration 18, loss = 0.09545598\n",
      "Iteration 19, loss = 0.09607034\n",
      "Iteration 20, loss = 0.09212446\n",
      "Iteration 21, loss = 0.09084610\n",
      "Iteration 22, loss = 0.08659692\n",
      "Iteration 23, loss = 0.08690280\n",
      "Iteration 24, loss = 0.08385008\n",
      "Iteration 25, loss = 0.08326281\n",
      "Iteration 26, loss = 0.08400651\n",
      "Iteration 27, loss = 0.08395280\n",
      "Iteration 28, loss = 0.11036444\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.38698097\n",
      "Iteration 2, loss = 0.28520679\n",
      "Iteration 3, loss = 0.22981052\n",
      "Iteration 4, loss = 0.19866811\n",
      "Iteration 5, loss = 0.17566201\n",
      "Iteration 6, loss = 0.16996563\n",
      "Iteration 7, loss = 0.15618181\n",
      "Iteration 8, loss = 0.22446616\n",
      "Iteration 9, loss = 0.14737955\n",
      "Iteration 10, loss = 0.13064983\n",
      "Iteration 11, loss = 0.12421650\n",
      "Iteration 12, loss = 0.11811615\n",
      "Iteration 13, loss = 0.11051142\n",
      "Iteration 14, loss = 0.10759475\n",
      "Iteration 15, loss = 0.10481650\n",
      "Iteration 16, loss = 0.09956810\n",
      "Iteration 17, loss = 0.09727642\n",
      "Iteration 18, loss = 0.09320962\n",
      "Iteration 19, loss = 0.09173985\n",
      "Iteration 20, loss = 0.09157152\n",
      "Iteration 21, loss = 0.08788964\n",
      "Iteration 22, loss = 0.08607108\n",
      "Iteration 23, loss = 0.08915649\n",
      "Iteration 24, loss = 0.10232392\n",
      "Iteration 25, loss = 0.08584608\n",
      "Iteration 26, loss = 0.08130130\n",
      "Iteration 27, loss = 0.08371145\n",
      "Iteration 28, loss = 0.16202726\n",
      "Iteration 29, loss = 0.11699226\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.39190492\n",
      "Iteration 2, loss = 0.28452639\n",
      "Iteration 3, loss = 0.24938615\n",
      "Iteration 4, loss = 0.21041736\n",
      "Iteration 5, loss = 0.18005568\n",
      "Iteration 6, loss = 0.16675027\n",
      "Iteration 7, loss = 0.15201235\n",
      "Iteration 8, loss = 0.16526319\n",
      "Iteration 9, loss = 0.13436269\n",
      "Iteration 10, loss = 0.13697477\n",
      "Iteration 11, loss = 0.12107048\n",
      "Iteration 12, loss = 0.11667339\n",
      "Iteration 13, loss = 0.11103042\n",
      "Iteration 14, loss = 0.10950596\n",
      "Iteration 15, loss = 0.11129761\n",
      "Iteration 16, loss = 0.10336334\n",
      "Iteration 17, loss = 0.09995632\n",
      "Iteration 18, loss = 0.09435230\n",
      "Iteration 19, loss = 0.10277755\n",
      "Iteration 20, loss = 0.09749407\n",
      "Iteration 21, loss = 0.08964161\n",
      "Iteration 22, loss = 0.09511067\n",
      "Iteration 23, loss = 0.11917350\n",
      "Iteration 24, loss = 0.09009605\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.39308011\n",
      "Iteration 2, loss = 0.28570300\n",
      "Iteration 3, loss = 0.23535190\n",
      "Iteration 4, loss = 0.22321196\n",
      "Iteration 5, loss = 0.19336619\n",
      "Iteration 6, loss = 0.16956843\n",
      "Iteration 7, loss = 0.15783624\n",
      "Iteration 8, loss = 0.15144097\n",
      "Iteration 9, loss = 0.13638851\n",
      "Iteration 10, loss = 0.15252847\n",
      "Iteration 11, loss = 0.14871346\n",
      "Iteration 12, loss = 0.12408308\n",
      "Iteration 13, loss = 0.11424790\n",
      "Iteration 14, loss = 0.11050621\n",
      "Iteration 15, loss = 0.10426818\n",
      "Iteration 16, loss = 0.10282350\n",
      "Iteration 17, loss = 0.09944018\n",
      "Iteration 18, loss = 0.09380094\n",
      "Iteration 19, loss = 0.09269244\n",
      "Iteration 20, loss = 0.09286106\n",
      "Iteration 21, loss = 0.08768003\n",
      "Iteration 22, loss = 0.09205011\n",
      "Iteration 23, loss = 0.10597650\n",
      "Iteration 24, loss = 0.08651939\n",
      "Iteration 25, loss = 0.08391317\n",
      "Iteration 26, loss = 0.08534003\n",
      "Iteration 27, loss = 0.08410900\n",
      "Iteration 28, loss = 0.08427225\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.38706241\n",
      "Iteration 2, loss = 0.28255256\n",
      "Iteration 3, loss = 0.23049432\n",
      "Iteration 4, loss = 0.20180769\n",
      "Iteration 5, loss = 0.17717936\n",
      "Iteration 6, loss = 0.16178376\n",
      "Iteration 7, loss = 0.15021221\n",
      "Iteration 8, loss = 0.13718237\n",
      "Iteration 9, loss = 0.16825668\n",
      "Iteration 10, loss = 0.12540542\n",
      "Iteration 11, loss = 0.11612399\n",
      "Iteration 12, loss = 0.10940787\n",
      "Iteration 13, loss = 0.10582928\n",
      "Iteration 14, loss = 0.10308228\n",
      "Iteration 15, loss = 0.12313812\n",
      "Iteration 16, loss = 0.09798474\n",
      "Iteration 17, loss = 0.09366842\n",
      "Iteration 18, loss = 0.08988267\n",
      "Iteration 19, loss = 0.08855160\n",
      "Iteration 20, loss = 0.09133073\n",
      "Iteration 21, loss = 0.08545720\n",
      "Iteration 22, loss = 0.08259001\n",
      "Iteration 23, loss = 0.08297788\n",
      "Iteration 24, loss = 0.08268240\n",
      "Iteration 25, loss = 0.08133864\n",
      "Iteration 26, loss = 0.08105042\n",
      "Iteration 27, loss = 0.07883693\n",
      "Iteration 28, loss = 0.08352102\n",
      "Iteration 29, loss = 0.12294329\n",
      "Iteration 30, loss = 0.10074191\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=500, alpha=0.0001,\n",
    "                     solver='sgd', verbose=10,  random_state=21,tol=0.000000001)\n",
    "results = []\n",
    "cv_results = cross_val_score(clf, x, y, cv=10, scoring=\"accuracy\")\n",
    "cv_results_f_mlp = cross_val_score(clf, x, y, cv=10, scoring=\"f1\")\n",
    "results.append(cv_results)\n",
    "results.append(cv_results_f_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Decision Tree Classifier: DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "\n",
    "cv_results = cross_val_score(clf, x, y, cv=10, scoring=\"accuracy\")\n",
    "cv_results_f_tree = cross_val_score(clf, x, y, cv=10, scoring=\"f1\")\n",
    "results.append(cv_results)\n",
    "results.append(cv_results_f_mlp)\n",
    "results.append(cv_results_f_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import graphviz \n",
    "# dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "# graph = graphviz.Source(dot_data) \n",
    "# graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## T Test where A is MLPClassifier and B is DecisionTreeClassifier\n",
    "Null Hypothesis:  There is no statistically significantly better classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_Test between MLPClassifier & DecisionTreeClassifier: T Value = -8.55448608048, P Value = 8.49922930944e-07\n",
      "MLPClassifier is statistically significantly worse than DecisionTreeClassifier\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from scipy import stats\n",
    "t_prime, p = stats.ttest_ind(results[0], results[1], equal_var=False)\n",
    "t = float(1.96)\n",
    "print(\"T_Test between {} & {}: T Value = {}, P Value = {}\".format(\"MLPClassifier\", \"DecisionTreeClassifier\", t_prime, p))\n",
    "if (t_prime >= t):\n",
    "    print(\"MLPClassifier is statistically significantly better than DecisionTreeClassifier\")\n",
    "elif (t_prime <= -t): \n",
    "    print(\"MLPClassifier is statistically significantly worse than DecisionTreeClassifier\")\n",
    "else: \n",
    "    print(\"There is no statistically significant difference.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## F-Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_Test between MLPClassifier & DecisionTreeClassifier: T Value = -5.32803812636, P Value = 0.000203255046296\n",
      "MLPClassifier is statistically significantly worse than DecisionTreeClassifier\n"
     ]
    }
   ],
   "source": [
    "t_prime, p = stats.ttest_ind(results[2], results[3], equal_var=False)\n",
    "t = float(1.96)\n",
    "print(\"T_Test between {} & {}: T Value = {}, P Value = {}\".format(\"MLPClassifier\", \"DecisionTreeClassifier\", t_prime, p))\n",
    "if (t_prime >= t):\n",
    "    print(\"MLPClassifier is statistically significantly better than DecisionTreeClassifier\")\n",
    "elif (t_prime <= -t): \n",
    "    print(\"MLPClassifier is statistically significantly worse than DecisionTreeClassifier\")\n",
    "else: \n",
    "    print(\"There is no statistically significant difference.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
